{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2E5wsEF3tOfK"
      },
      "outputs": [],
      "source": [
        "from yolov3 import cfg\n",
        "from yolov3.utils import *\n",
        "from yolov3.visualize import *\n",
        "\n",
        "model=cfg.MODEL\n",
        "\n",
        "img_path='C:/Users/phiho/Projects/GAN_Yolov5/Dataset/train_dog_cat_person/299x299/dog/000000002754_3.jpg'\n",
        "class_names=cfg.CLASS_NAMES\n",
        "device=cfg.DEVICE\n",
        "save_to='yolov3/preds/dog.jpg'\n",
        "model.eval()\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import torchvision\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, target_size=(608, 608), device='cpu'):\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root_dir, transform=transform)\n",
        "        self.target_size = target_size\n",
        "        self.device = device\n",
        "        self.img_paths = [path for path, _ in self.dataset.samples]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img, label = self.dataset[idx]\n",
        "        img = cv2.cvtColor(img.cpu().numpy().transpose((1, 2, 0)), cv2.COLOR_RGB2BGR)\n",
        "        img = cv2.resize(img, self.target_size)\n",
        "        img = torch.from_numpy(img.transpose(2, 0, 1)).float().unsqueeze(0)\n",
        "        img = img.to(self.device)\n",
        "\n",
        "        return img, label, img_path\n",
        "    \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "COCO_ROOT = \"C:/Users/phiho/Projects/Dataset/MS-COCO/COCO_81/coco81/\"\n",
        "# Tạo dataset\n",
        "coco_dataset = CustomDataset(root_dir=COCO_ROOT, \n",
        "                             transform=transforms.ToTensor(), \n",
        "                             target_size=(608, 608), \n",
        "                             device=device)\n",
        "dataloader = DataLoader(coco_dataset, batch_size=32, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "for i, data in tqdm(enumerate(dataloader, start=0)):\n",
        "    images,labels,p = data\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 608, 608])\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "axes don't match array",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, im \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(im\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 8\u001b[0m     im \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(im\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)), cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n\u001b[0;32m      9\u001b[0m     im \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(im, (\u001b[38;5;241m608\u001b[39m, \u001b[38;5;241m608\u001b[39m))\n\u001b[0;32m     10\u001b[0m     im \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(im\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: axes don't match array"
          ]
        }
      ],
      "source": [
        "nms_thresh = 0.5\n",
        "conf_thres = 0.0005\n",
        "batch = images.shape[0]\n",
        "res = torch.zeros(batch, 80).to(device)\n",
        "images = images.to(device)\n",
        "for j, im in enumerate(images):\n",
        "    print(im.shape)\n",
        "    im = cv2.cvtColor(im.cpu().detach().numpy().transpose((1, 2, 0)), cv2.COLOR_RGB2BGR)\n",
        "    im = cv2.resize(im, (608, 608))\n",
        "    im = torch.from_numpy(im.transpose(2, 0, 1)).float().unsqueeze(0)\n",
        "    im = im.to(device)\n",
        "    output = model(im)\n",
        "    boxes = []\n",
        "    for i in range(3):\n",
        "        boxes += find_all_boxes_2(\n",
        "            output[i].data,\n",
        "            device,\n",
        "            conf_thres,\n",
        "            model.num_classes,\n",
        "            model.anchors[i],\n",
        "            model.num_anchors)[0]\n",
        "    boxes = nms_combined(boxes, nms_thresh)\n",
        "    res = torch.zeros((80), device=device)\n",
        "    conf = boxes[:, -2]\n",
        "    cls = boxes[:, -1].long()\n",
        "    for c in range(80):\n",
        "        mask = (cls == c)\n",
        "        if mask.any():\n",
        "            res[j][c] = conf[mask].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62\n",
            "8\n",
            "Standard 8\n"
          ]
        }
      ],
      "source": [
        "j = 213332\n",
        "conf_thresh=0.001\n",
        "nms_thresh=0.5\n",
        "# img = cv2.cvtColor(coco_dataset[j][0].cpu().numpy().transpose((1, 2, 0)), cv2.COLOR_RGB2BGR)\n",
        "# img = cv2.resize(img, (608, 608))\n",
        "# img = torch.from_numpy(img.transpose(2, 0, 1)).float().unsqueeze(0)\n",
        "# img = img.to(device)\n",
        "img = coco_dataset[j][0]\n",
        "output = model(img)\n",
        "\n",
        "boxes = []\n",
        "for i in range(3):\n",
        "    boxes += find_all_boxes_2(\n",
        "        output[i].data,\n",
        "        device,\n",
        "        conf_thresh,\n",
        "        model.num_classes,\n",
        "        model.anchors[i],\n",
        "        model.num_anchors)[0]\n",
        "\n",
        "boxes = nms_combined(boxes, nms_thresh)\n",
        "\n",
        "# pred_img = plot_boxes_cv2(cv2.imread(img_path), [], save_to, class_names)\n",
        "# pred_img = plot_boxes_cv2(cv2.cvtColor(coco_dataset[j][0].cpu().numpy().transpose((1, 2, 0)), cv2.COLOR_RGB2BGR)*255, boxes, save_to, class_names)\n",
        "# pred_img = plot_boxes_cv2(coco_dataset[j][0].squeeze(0).cpu().numpy().transpose((1, 2, 0), boxes, save_to, class_names)\n",
        "# pred_img\n",
        "# print(coco_dataset[j][2])\n",
        "# print(boxes)\n",
        "# for *_, conf, cls in boxes:\n",
        "#     print(f\"{class_names[int(cls.item())]} : {conf.item()}\")\n",
        "res = torch.zeros((80), device=device)\n",
        "conf = boxes[:, -2]\n",
        "cls = boxes[:, -1].long()\n",
        "res.scatter_add_(0, cls, conf)\n",
        "print(torch.argmax(res).item())\n",
        "\n",
        "res = torch.zeros((80), device=device)\n",
        "conf = boxes[:, -2]\n",
        "cls = boxes[:, -1].long()\n",
        "for c in range(80):\n",
        "    mask = (cls == c)\n",
        "    if mask.any():\n",
        "        res[c] = conf[mask].max()\n",
        "print(torch.argmax(res).item())\n",
        "\n",
        "res = torch.zeros((80), device=device)\n",
        "for *_, conf, cls in boxes:\n",
        "    c = int(cls.item())\n",
        "    if res[c] < conf:\n",
        "        res[c] = conf\n",
        "print('Standard', torch.argmax(res).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "213"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "random_number = torch.randint(0, 80, (1,)).item()  # Tạo một số nguyên ngẫu nhiên từ 0 đến 79\n",
        "print(random_number)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predict(\n",
        "    model=cfg.MODEL,\n",
        "    conf_thresh=0.7,\n",
        "    nms_thresh=0.5,\n",
        "    img_path='C:/Users/phiho/Projects/GAN_Yolov5/Dataset/train_dog_cat_person/299x299/dog/000000002754_3.jpg',\n",
        "    class_names=cfg.CLASS_NAMES,\n",
        "    device=cfg.DEVICE,\n",
        "    save_to='yolov3/preds/dog.jpg'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "yolov2.torch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
